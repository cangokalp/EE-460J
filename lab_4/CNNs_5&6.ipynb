{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "ds_lab",
      "language": "python",
      "name": "ds_lab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "CNNs_5&6.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-MY5Yh5SVFW"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSCYqu4FSVFh"
      },
      "source": [
        "# from sklearn.datasets import fetch_openml\n",
        "# mnist = fetch_openml('mnist_784', version=1)\n",
        "# mnist.keys()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ysaeCwSVFn"
      },
      "source": [
        "# X, y = mnist['data'], mnist['target']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTFD8-iuSVFs"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcS-9_kbmZ5t"
      },
      "source": [
        "### Getting Started with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkP-ND5AeCjK"
      },
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlnUV_4ceDm7"
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((X_train, y_train), (X_test, y_test), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn3PkdT4SVFw"
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train - X_mean) / X_std\n",
        "X_test = (X_test - X_mean) / X_std\n",
        "\n",
        "X_train, y_train, X_test, y_test = map(\n",
        "    torch.tensor, (X_train, y_train, X_test, y_test)\n",
        ")\n",
        "\n",
        "\n",
        "bs = 64"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW-JA5YGSVF0"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "test_ds = TensorDataset(X_test, y_test)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZgzidixSVF3"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_data(train_ds, test_ds, bs=64):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(test_ds, batch_size=bs * 2),\n",
        "    )"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd4jqMBPSVF7"
      },
      "source": [
        "train_dl, test_dl = get_data(train_ds, test_ds)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI3RMw-uSVF_"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X3Fv0CBh8kY"
      },
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uo-b4y2SVGC"
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "objy4wZPSVGE"
      },
      "source": [
        "def preprocess(x, y, p=28):\n",
        "    return x.view(-1, 1, p, p), y\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))\n",
        "\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "test_dl = WrappedDataLoader(test_dl, preprocess)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AU4a8UBSVGG"
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    epoch_train_loss = []\n",
        "    epoch_test_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        train_nums = []\n",
        "        for xb, yb in train_dl:\n",
        "            losses, nums = loss_batch(model, loss_func, xb, yb, opt)\n",
        "            train_losses.append(losses)\n",
        "            train_nums.append(nums)\n",
        "        train_loss = np.sum(np.multiply(np.array(train_losses), np.array(train_nums))) / np.sum(train_nums)\n",
        "        epoch_train_loss.append(train_loss)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in test_dl]\n",
        "            )\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "        epoch_test_loss.append(val_loss)\n",
        "\n",
        "        print('epoch #: {}, train_loss: {}, val_loss: {}'.format(epoch, train_loss, val_loss))\n",
        "        print('train_accuracy: {}, val_accuracy: {}'.format(accuracy(model(X_train.view(-1,1,28,28)), y_train), accuracy(model(X_test.view(-1,1,28,28)), y_test)))\n",
        "        print('=======================================')\n",
        "\n",
        "    return = epoch_train_loss, epoch_test_loss\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS3taHWtcyiD"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaLFx2d5SVGJ",
        "outputId": "4dfd5a74-ba58-4cc5-c68f-4bd6cd46efda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    # Lambda(lambda x: x.view(x.size(0), -1)),\n",
        "    nn.Flatten(),\n",
        ")\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 15\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, test_dl)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch #: 0, train_loss: 0.9990334366989135, val_loss: 0.6126176641464234\n",
            "train_accuracy: 0.8108000159263611, val_accuracy: 0.8306000232696533\n",
            "=======================================\n",
            "epoch #: 1, train_loss: 0.4234979261302948, val_loss: 0.3990812261104584\n",
            "train_accuracy: 0.8687800168991089, val_accuracy: 0.8787000179290771\n",
            "=======================================\n",
            "epoch #: 2, train_loss: 0.3782279883813858, val_loss: 0.37200057525634767\n",
            "train_accuracy: 0.8808199763298035, val_accuracy: 0.8899000287055969\n",
            "=======================================\n",
            "epoch #: 3, train_loss: 0.34477763493537905, val_loss: 0.2861241530478001\n",
            "train_accuracy: 0.9217000007629395, val_accuracy: 0.9280999898910522\n",
            "=======================================\n",
            "epoch #: 4, train_loss: 0.3223202053833008, val_loss: 0.3282582637667656\n",
            "train_accuracy: 0.8959000110626221, val_accuracy: 0.9042999744415283\n",
            "=======================================\n",
            "epoch #: 5, train_loss: 0.29471539058685303, val_loss: 0.2514480815410614\n",
            "train_accuracy: 0.9236599802970886, val_accuracy: 0.9271000027656555\n",
            "=======================================\n",
            "epoch #: 6, train_loss: 0.2965756346416473, val_loss: 0.24965343329906464\n",
            "train_accuracy: 0.9161400198936462, val_accuracy: 0.9262999892234802\n",
            "=======================================\n",
            "epoch #: 7, train_loss: 0.27067227903604507, val_loss: 0.2110320549815893\n",
            "train_accuracy: 0.9291800260543823, val_accuracy: 0.9369000196456909\n",
            "=======================================\n",
            "epoch #: 8, train_loss: 0.25942745501041414, val_loss: 0.2436994205445051\n",
            "train_accuracy: 0.921019971370697, val_accuracy: 0.9284999966621399\n",
            "=======================================\n",
            "epoch #: 9, train_loss: 0.27867434278965, val_loss: 0.24949833046197892\n",
            "train_accuracy: 0.930679976940155, val_accuracy: 0.9316999912261963\n",
            "=======================================\n",
            "epoch #: 10, train_loss: 0.2824636505532265, val_loss: 0.20793145570755006\n",
            "train_accuracy: 0.9384199976921082, val_accuracy: 0.9423999786376953\n",
            "=======================================\n",
            "epoch #: 11, train_loss: 0.2540394369274378, val_loss: 0.2277076188519597\n",
            "train_accuracy: 0.9339799880981445, val_accuracy: 0.940500020980835\n",
            "=======================================\n",
            "epoch #: 12, train_loss: 0.2541359584146738, val_loss: 0.21670233496427535\n",
            "train_accuracy: 0.9373199939727783, val_accuracy: 0.9456999897956848\n",
            "=======================================\n",
            "epoch #: 13, train_loss: 0.23567955658197404, val_loss: 0.18410864196121693\n",
            "train_accuracy: 0.9439799785614014, val_accuracy: 0.9490000009536743\n",
            "=======================================\n",
            "epoch #: 14, train_loss: 0.23237197889089584, val_loss: 0.18695897841975093\n",
            "train_accuracy: 0.9467999935150146, val_accuracy: 0.9505000114440918\n",
            "=======================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4U0MCN7md64"
      },
      "source": [
        "### CNNs for CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbeHr8H7SVGL",
        "outputId": "35adc238-5d88-466d-ab0f-324f2aa5ee9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "cifar_10_small = fetch_openml('CIFAR_10_Small', version=1)\n",
        "cifar_10_small.keys()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4UAm6_WSVGN"
      },
      "source": [
        "X_train, y_train = cifar_10_small['data'], cifar_10_small['target']"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGV0Lsl1WzrD",
        "outputId": "bef3074b-e2ec-44e7-e60c-bd07ae0f5433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-d66b50646508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJTxxDYPzOQm"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(64, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    # Lambda(lambda x: x.view(x.size(0), -1)),\n",
        "    nn.Flatten(),\n",
        ")\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "momentum = 0.9\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 10\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "train_losses, test_losses = fit(epochs, model, loss_func, opt, train_dl, test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTgdhl9K2aHK"
      },
      "source": [
        "plt.plot(train_losses, range(len(train_losses)), 'b-', legend='train' )\n",
        "plt.plot(test_losses, range(len(test_losses)), 'g--', legend='test')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Model 1: train_vs_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ZZ71Ns09X3"
      },
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64*16*16, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 19)\n",
        ")\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "momentum = 0.9\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 10\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "train_losses, test_losses = fit(epochs, model, loss_func, opt, train_dl, test_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Z1iOZ82c3l"
      },
      "source": [
        "plt.plot(train_losses, range(len(train_losses)), 'b-', legend='train' )\n",
        "plt.plot(test_losses, range(len(test_losses)), 'g--', legend='test')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Model 2: train_vs_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lAkpc-y3Gsl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}